{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from collections import Counter\n",
    "import glob\n",
    "import pickle\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from mpl_toolkits.axes_grid1 import AxesGrid\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.optimizers import SGD, Adam\n",
    "from random import shuffle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir_path in glob.glob('../Bootcamp/spectrogram_final/*.png'):\n",
    "    if(dir_path.split('/')[3] == '694.png'):\n",
    "        continue\n",
    "    img = cv2.imread(dir_path)\n",
    "    #crop full audio spectograms to obtain 0-30s spectograms and 30-60s spectograms\n",
    "    crop1 = img[:,0:200] #0-30 s\n",
    "    crop2 = img[:,200:400] #30-60 s\n",
    "    cv2.imwrite('../Bootcamp/0-30/'+dir_path.split('/')[3],crop1)\n",
    "    cv2.imwrite('../Bootcamp/30-60/'+dir_path.split('/')[3],crop2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_genre = {\n",
    "    0:'Pop',\n",
    "    1:'Rock',\n",
    "    2:'Jazz'\n",
    "}\n",
    "\n",
    "reverse_genre = {\n",
    "    'Pop':0,\n",
    "    'Rock':1,\n",
    "    'Jazz':2\n",
    "}\n",
    "\n",
    "batch_size = 100\n",
    "epochs = 5\n",
    "num_classes = len(map_genre)\n",
    "input_shape = (200,362,3)\n",
    "\n",
    "\n",
    "def create_model_six_conv(input_shape):\n",
    "    \"\"\"\n",
    "    CNN Keras model with 6 convolutions.\n",
    "    :param input_shape: input shape, generally X_train.shape[1:]\n",
    "    :return: Keras model, RMS prop optimizer\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same')) \n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(256, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    opt = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    return model, opt\n",
    "\n",
    "def load_model_from_checkpoint(weights_path, input_shape=(200,362,3)):\n",
    "    model, opt = create_model_six_conv(input_shape)\n",
    "    model.load_weights(weights_path)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "    return model\n",
    "  \n",
    "def load_test_set(path):\n",
    "    pics, labels = [], []\n",
    "    reverse_dict = {v:k for k,v in map_characters.items()}\n",
    "    for pic in glob.glob(path+'*.*'):\n",
    "        char_name = \"_\".join(pic.split('/')[3].split('_')[:-1])\n",
    "#         temp = pic.split('/')[2].split('\\\\')[1]\n",
    "#         char_name = \"_\".join(temp.split('_')[:-1])\n",
    "        if char_name in reverse_dict:\n",
    "            temp = cv2.imread(pic)\n",
    "            temp = cv2.resize(temp, (200,362)).astype('float32') / 255.\n",
    "            pics.append(temp)\n",
    "            labels.append(reverse_dict[char_name])\n",
    "    X_test = np.array(pics)\n",
    "    y_test = np.array(labels)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes) #pic in hpoen\n",
    "    print(\"Test set\", X_test.shape, y_test.shape)\n",
    "    return X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0_train, X0_test, y0_train, y0_test = [],[],[],[]\n",
    "data0_data, data0_target = [],[]\n",
    "data30_data, data30_target = [],[]\n",
    "\n",
    "annotation = pd.read_csv('annotation.csv')\n",
    "label = annotation['genre 1']\n",
    "label = label.replace(reverse_genre)\n",
    "pic_number = annotation['file_audio']\n",
    "annotation['index_code'] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "998"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(glob.glob('../Bootcamp/0-30/*.png')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelling = []\n",
    "for dir_path in glob.glob('../Bootcamp/0-30/*.png'):\n",
    "    numpic = dir_path.split('/')[3]\n",
    "    numpic = numpic.split('.')[0]\n",
    "    file_index = int(numpic)\n",
    "    temp_1 = annotation[annotation['file_audio']==file_index]['index_code']\n",
    "    data0_target.append(temp_1.iloc[0])\n",
    "    temp1 = cv2.imread(dir_path)\n",
    "    temp1 = cv2.resize(temp1, (200,362)).astype('float32')\n",
    "    data0_data.append(temp1)\n",
    "    \n",
    "for dir_path in glob.glob('../Bootcamp/30-60/*.png'):\n",
    "    numpic1 = dir_path.split('/')[3]\n",
    "    numpic1 = numpic.split('.')[0]\n",
    "    file_index1 = int(numpic1)\n",
    "    temp_2 = annotation[annotation['file_audio']==file_index1]['index_code']\n",
    "    data30_target.append(temp_2.iloc[0])\n",
    "    temp2 = cv2.imread(dir_path)\n",
    "    temp2 = cv2.resize(temp1, (200,362)).astype('float32')\n",
    "    data30_data.append(temp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelling1 = annotation[annotation['file_audio'] == 692]['index_code']\n",
    "label15 = []\n",
    "label15.append(labelling1.iloc[0])\n",
    "labelling1 = annotation[annotation['file_audio'] == 100]['index_code']\n",
    "label15.append(labelling1.iloc[0])\n",
    "label15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "998"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(data0_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "998"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(data30_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harryramli/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "#train test split to split data into training, testing and labelling of data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X0_train, X0_test, y0_train, y0_test = train_test_split(data0_data,data0_target,test_size = 0.33, random_state = 42)\n",
    "X30_train, X30_test, y30_train, y30_test = train_test_split(data30_data,data30_target,test_size = 0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0-30s \n",
    "X0_train = np.array(X0_train)\n",
    "X0_test = np.array(X0_test)\n",
    "y0_train = keras.utils.to_categorical(y0_train,num_classes)\n",
    "y0_test = keras.utils.to_categorical(y0_test,num_classes)\n",
    "\n",
    "#30-60s\n",
    "X30_train = np.array(X30_train)\n",
    "X30_test = np.array(X30_test)\n",
    "y30_train = keras.utils.to_categorical(y30_train,num_classes)\n",
    "y30_test = keras.utils.to_categorical(y30_test,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 668 samples, validate on 330 samples\n",
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "#creating CNN model to test 0-30s data\n",
    "model , opt = create_model_six_conv(input_shape=(362,200,3))\n",
    "model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
    "model.fit(X0_train,y0_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(X0_test,y0_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
